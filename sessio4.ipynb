{
 "metadata": {
  "name": "",
  "signature": "sha256:4cb62f7e70c103a3b3f7f3da6b9bcd8e490579149ec27bc4fea4c72d215b4e19"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sessi\u00f3 4"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creaci\u00f3 de l'esquelet del nostre Building-Recognizer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Aquesta setmana hem programat les bases del que ser\u00e0 el nostre projecte.\n",
      "Est\u00e0 dividit en 6 funcions: build database, feature extraction, ranking, ranking evaluation, classification i classification evaluation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Build database"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "build_database.py te la funci\u00f3 de crear un fitxer de text amb les id's a partir de les dades que tenim."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os # llibreria os per poder accedir al directori de treball\n",
      "def build_database(dir_entrada,val_or_train,dir_sortida):\n",
      "    images = os.listdir(dir_entrada) #Llegim el nom dels fitxers que hi ha en el directori que volem (el d'entrada)\n",
      "    outfile = open(dir_sortida+'/outfile_'+val_or_train+'.txt','w') # Creem un fitxer per guardar les id's  \n",
      "    for file in images:\n",
      "        outfile.write(file[0:-4]+\"\\n\") #cada linea del nou fitxer ser\u00e0 el nom de les imatge que hi ha en el directori menys l'extensio .jpg\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #ruta absoluta del projecte   \n",
      "build_database(ruta+'/TerrassaBuildings900/train/images',\"train\",ruta+'/files'); #creacio train database\n",
      "build_database(ruta+'/TerrassaBuildings900/val/images',\"val\",ruta+'/files'); #creacio val database"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output de la funci\u00f3 serien dos fitxers .txt un per train i un altre per val amb el format seguent:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "10746-4356-24457\n",
      "10956-21869-28493 \n",
      "11072-19559-2960 \n",
      "11088-24299-26324\n",
      "11485-2695-23379\n",
      "11776-28585-22785 \n",
      "11783-18760-3162\n",
      "1186-2911-12546\n",
      "11929-2134-25457\n",
      "11962-11431-11239\n",
      "12201-19278-27341\n",
      "12297-2961-2691\n",
      "12678-16441-5334\n",
      "..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Image descriptors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "get_features.py te la funci\u00f3 de donat un directori amb imatges i un text amb les ID's(build_database) ens crea un diccionari en que la KEY ser\u00e0 l'ID de la imatge i aix\u00f2 anir\u00e0 associat amb un vector de tamany 100 que de moment estar\u00e0 omplert amb n\u00fameros aleatoris"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pickle\n",
      "import os #carreguem la llibreria os per tal d'obtenir la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "def getfeatures(val_or_train):\n",
      "    IDs_file = open(ruta+\"/files/outfile_\"+val_or_train+\".txt\", 'r') #obrim l'arxiu que cont\u00e9 les ids de les imatges\n",
      "    features_file = open(ruta + \"/files/features_\"+val_or_train+\".p\",'w') #obrim l'arxiu en el que escriurem les caracteristiques\n",
      "    feat_vec = dict() #inicialitzem el diccionari buit\n",
      "    for line in IDs_file:\n",
      "        features = np.random.rand(1,100)#Generem el vector de caracteristiques aleatori\n",
      "        final = line.index(\"\\n\") #obtenim la posici\u00f3 del salt de l\u00ednia\n",
      "        feat_vec[line[0:final]] = features #afegim el vector de caracteristiques aleatori al diccionari\n",
      "    IDs_file.close() #tanquem l'arxiu que cont\u00e9 nom\u00e9s les ids de les imatges\n",
      "    pickle.dump(feat_vec, features_file) #escribim el diccionari amb pickle\n",
      "    features_file.close() #tanquem l'arxiu del diccionari\n",
      "getfeatures(\"train\") #cridem a la funcio en mode train\n",
      "getfeatures(\"val\") #cridem a la funci\u00f3 en mode val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output d'aquesta funci\u00f3 es un archiu .p el qual hem creat amb l'ajuda de la llibreria pickle."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ranking"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "rank.py a partir del diccionari de caracter\u00edstiques creat per la funci\u00f3 get_features, ens crea un fitxer .txt per cada key del diccionari de validaci\u00f3 o de test (en aquest cas nom\u00e9s de validaci\u00f3)en el que de moment l'ordre ser\u00e0 aleatori."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import os\n",
      "import pickle #carreguem la llibreria pickle per poder treballar amb els diccionaris\n",
      "import random #carreguem la llibreria que utilitzarem per fer el r\u00e0nking aleatori de cada fitxer.\n",
      "import numpy as np\n",
      "\n",
      "def rank(features_path,save_path,features_train,val_or_test):\n",
      "    out = []\n",
      "    featuresfile = open(features_path+'/features_'+val_or_test+'.p','r') #obrim el diccionari de vectors de caracter\u00edstiques de validaci\u00f3 o de test\n",
      "    train_featuresfile = open(features_train,'r') #obrim el diccionari de vectors de caracter\u00edstiques d'entrenament\n",
      "    rankfiles = pickle.load(featuresfile) #carreguem el diccionari validaci\u00f3 o test\n",
      "    train = pickle.load(train_featuresfile) #carreguem el diccionari entrenament\n",
      "    for k in rankfiles.keys(): #per cada clau del diccionari dels vectors de caracteristiques de validaci\u00f3\n",
      "                                #o test ens crear\u00e0 un fitxer .txt guardat a la seva carpeta corresponent,\n",
      "                                #el qual tindr\u00e0 el r\u00e0nking aleatori de les claus del diccionari d'entrenament\n",
      "        outfile = open(save_path+'/ranking_'+val_or_test+'/'+k+'.txt','w')\n",
      "        for k in train.keys():\n",
      "            out.insert(np.random.randint(0,451),k)\n",
      "        for item in out:\n",
      "            outfile.write(\"%s\\n\" % item)\n",
      "        out = []\n",
      "        outfile.close()\n",
      "    featuresfile.close()\n",
      "    train_featuresfile.close()\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #ruta absoluta del projecte\n",
      "rank(ruta+'/files',ruta+'/files',ruta+'/files/features_train.p',\"val\") #crida a la funci\u00f3 rank pel diccionari de validaci\u00f3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0n una serie d'arxius .txt amb el seg\u00fcent format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "14688-12819-23815\n",
      "8102-608-557\n",
      "17469-21378-15783\n",
      "15716-25710-4269\n",
      "22707-18292-31031\n",
      "10965-12763-11660\n",
      "211-18679-31286\n",
      "2593-20393-27590\n",
      "12487-11017-3187\n",
      "..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "classify.py a partir del diccionari de caracter\u00edstiques creat per la funci\u00f3 get_features, i d'un txt amb les possibles labels ens retorna un .txt amb les ID's classificades."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import os #carreguem la llibreria os per tal d'obtenir la ruta absoluta de la carpeta del projecte\n",
      "import random #carreguem la llibreria d'aleatori\n",
      "import pickle\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "def classify(features,save_to,labels,val_or_test):\n",
      "    infile_features = open(features,'r') #obrim el fitxer on estan les features\n",
      "    #infile_labels = open(labels,'r') #obrim el fitxer on estan les possibles labels\n",
      "    outfile = open(save_to+'/classification_'+val_or_test+'.txt', 'w'); #Creem un fitxer on guardar les classificacions\n",
      "    outfile.write(\"ImageID\" \"\\t\" \"ClassID\" \"\\n\")\n",
      "    features = pickle.load(infile_features)\n",
      "    \n",
      "    for k in features.keys():\n",
      "        outfile.write(k + \"\\t\" + random.choice(open(labels).readlines()))\n",
      "    outfile.close()\n",
      "    \n",
      "classify(ruta+'/files/features_val.p',ruta+\"/files\", ruta+\"/files/labels.txt\", \"val\"); #crida a funci\u00f3 random_classification."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0 un .txt amb un format de \"ID   Label\" com el seg\u00fcent:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ImageID\tClassID\n",
      "18339-31531-15817\testacio_nord\n",
      "12487-11017-3187\tteatre_principal\n",
      "12628-28165-25479\tfarmacia_albinyana\n",
      "24970-14942-21710\tajuntament\n",
      "30042-22591-15462\tmercat_independencia\n",
      "23706-19407-15700\tmercat_independencia\n",
      "..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ranking Evaluation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "evaluate_ranking.py a partir de els .txt de ranking i del .txt de ground truth ens dona l'average precision i el mean average precision, hem utilitzat les llibreries d'sklearn.metrics per fer aquestes operacions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import numpy as np\n",
      "import os\n",
      "from itertools import islice\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "def evaluate_rank(dir_rank):\n",
      "    nfiles = os.listdir(dir_rank)\n",
      "    ground_truth_val = open(ruta+\"/TerrassaBuildings900/val/annotation.txt\", \"r\")\n",
      "    ground_truth_train = open(ruta+\"/TerrassaBuildings900/train/annotation.txt\",\"r\")\n",
      "    truth = {} #inicialitzem una taula on l'index es la id de la imatge i cont\u00e9 la seva categoria\n",
      "    it_ground_truth_val = islice(ground_truth_val,1,None)#eliminem la primera linia de l'arxiu ja que no ens interessa\n",
      "    it_ground_truth_train = islice(ground_truth_train,1,None)#eliminem la primera linia de l'arxiu ja que no ens interessa\n",
      "    for line in it_ground_truth_val:\n",
      "        id_foto = line.index(\"\\t\")\n",
      "        final = line.index(\"\\n\")\n",
      "        truth[line[0:id_foto]] = line[id_foto+1:final] #guardem la categoria de cada imatge a un vector\n",
      "    for line in it_ground_truth_train:\n",
      "        id_foto = line.index(\"\\t\")\n",
      "        final = line.index(\"\\n\")\n",
      "        truth[line[0:id_foto]] = line[id_foto+1:final] #guardem la categoria de cada imatge a un vector\n",
      "    for file in nfiles:\n",
      "        ranking = open(dir_rank+\"/\"+file,\"r\")\n",
      "        filename = file[0:file.index(\".\")]\n",
      "        categoria = truth[filename]\n",
      "        relevants = 0\n",
      "        irrelevants = 0\n",
      "        for line in ranking:\n",
      "            final = line.index(\"\\n\")\n",
      "            if truth[line[0:final]] == categoria: #si la id de la imatge coincideix amb la categoria sumem + 1 a relevants\n",
      "                relevants += 1\n",
      "            else:\n",
      "                irrelevants += 1\n",
      "            precision = float(relevants)/float((irrelevants+relevants))\n",
      "        ranking.close()\n",
      "        \n",
      "    #return ap, man #retornem tant la average precision com la mean average precision\n",
      "\n",
      "evaluate_rank(ruta + \"/files/ranking_val\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification Evaluation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "evaluate_classification.py a partir del .txt d'anotacions autom\u00e0tiques i del ground truth ens dona els seg\u00fcents par\u00e0metres: Accuracy, Precision / Recall / F1-score, Averaged Precision / Recall / F1-score i la matriu de confusi\u00f3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import os\n",
      "from itertools import islice\n",
      "#Afegim les llibreries de scikit, sklearn.metrics per poder fer tots els c\u00e0lculs\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import f1_score\n",
      "\n",
      "\n",
      "def evaluate_classification(automatic_classification, ground_truth, val_or_test):\n",
      "    automatic_annotation = open(automatic_classification+'/classification_'+val_or_test+'.txt','r') #obrim el fitxer generat per la funci\u00f3 classify\n",
      "    groundtruth_annotation = open(ground_truth, 'r') #obrim el fitxer d'annotacio donat\n",
      "    it_automatic = islice(automatic_annotation,1,None) #no tenim en compte la primera linia del fitxer generat pel classify\n",
      "    it_groundtruth = islice(groundtruth_annotation,1,None) # no tenim en compte la primera linia del fitxer donat.\n",
      "    automatic = []\n",
      "    ground_truth = []\n",
      "    for line in it_automatic:\n",
      "        inicio = line.index(\"\\t\")\n",
      "        final = len(line)\n",
      "        automatic.append(line[inicio:final]) #Afegim les categories a cada entrada de l'array\n",
      "    for line in it_groundtruth:\n",
      "        inicio = line.index(\"\\t\")\n",
      "        final = len(line)\n",
      "        ground_truth.append(line[inicio:final]) #Afegim les categories a cada entrada de l'array\n",
      "\n",
      "    # CALCULEM LA MATRIU DE CONFUSIO:\n",
      "    print(\"MATRIU DE CONFUSIO:\")\n",
      "    print(confusion_matrix(ground_truth,automatic))\n",
      "    print(\"\\n\")\n",
      "    \n",
      "    # CALCULEM L'ACCURACY\n",
      "    print(\"ACCURACY:\")\n",
      "    print(accuracy_score(ground_truth,automatic))\n",
      "    print(\"\\n\")\n",
      "    \n",
      "    # CALCULEM LA PRECISSION\n",
      "    print(\"PRECISSION:\")\n",
      "    print(precision_score(ground_truth,automatic,average='macro'))\n",
      "    print(\"\\n\")\n",
      "    \n",
      "    # CALCULEM EL RECALL\n",
      "    print(\"RECALL:\")\n",
      "    print(recall_score(ground_truth,automatic,average='macro'))\n",
      "    print(\"\\n\")\n",
      "    \n",
      "    # CALCULEM EL F1\n",
      "    print(\"F1:\")\n",
      "    print(f1_score(ground_truth,automatic,average='macro'))\n",
      "    print(\"\\n\")\n",
      "\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "evaluate_classification(ruta+'/files',ruta+'/TerrassaBuildings900/val/annotation.txt',\"val\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MATRIU DE CONFUSIO:\n",
      "[[ 0  0  0  0  0  1  2  1  0  1  3  1  1]\n",
      " [ 1  0  1  1  1  1  0  0  2  0  1  2  0]\n",
      " [ 1  1  0  2  0  1  0  0  0  0  1  1  3]\n",
      " [ 6  4  3  2  2  6  8 12  2  4  4  2  5]\n",
      " [ 0  0  1  0  0  0  0  3  2  0  2  1  1]\n",
      " [ 1  1  1  2  2  1  0  0  0  0  1  1  0]\n",
      " [ 2  0  0  0  1  1  0  0  3  1  1  0  1]\n",
      " [ 1  0  2  2  0  1  0  0  0  1  1  0  2]\n",
      " [ 1  1  2  2  0  2  0  0  0  0  2  0  0]\n",
      " [ 0  2  1  1  0  1  2  1  0  0  0  2  0]\n",
      " [ 0  1  1  1  1  1  0  2  1  0  1  1  0]\n",
      " [ 4  0  0  0  0  0  1  1  0  1  0  1  2]\n",
      " [ 0  0  0  3  0  1  0  0  2  4  0  0  0]]\n",
      "\n",
      "\n",
      "ACCURACY:\n",
      "0.0277777777778\n",
      "\n",
      "\n",
      "PRECISSION:\n",
      "0.0250754147813\n",
      "\n",
      "\n",
      "RECALL:\n",
      "0.025641025641\n",
      "\n",
      "\n",
      "F1:\n",
      "0.022437601385\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}